"""
src/graph/builder.py
å›¾æ„å»ºå™¨ - è´Ÿè´£ç»„è£… LangGraph
"""
from ..llms.qwen_llm import QwenLLM
from typing import Any, Callable, Dict, List
from langgraph.graph import StateGraph, END, START
from langgraph.constants import Send
import re

from .graph_config import SUBGRAPH_TOPOLOGY, MAIN_GRAPH_TOPOLOGY, EXECUTION_CONFIG
from ..state import SectionState, AgentState
from ..nodes.structure_node import generate_structure_node
from ..nodes.writer_node import write_section_node
from ..nodes.reflector_node import reflector_node, should_continue
from ..nodes.search_node import search_node
from ..utils import load_config


class SubGraphBuilder:
    """å­å›¾æ„å»ºå™¨"""
    
    def __init__(self, llm):
        self.llm = llm
        self.config = SUBGRAPH_TOPOLOGY
    
    def build(self) -> Any:
        """
        æ„å»ºå­å›¾
        
        æ‹“æ‰‘:
            START â†’ search â†’ write â†’ reflect â†’ format_output â†’ END
                      â†‘                â†“
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (æ¡ä»¶å¾ªç¯)
        """
        print("ğŸ”¨ æ„å»ºå­å›¾ (SectionWorker)...")
        
        workflow = StateGraph(SectionState)
        
        # æ·»åŠ èŠ‚ç‚¹
        self._add_nodes(workflow)
        
        # æ·»åŠ è¾¹
        self._add_edges(workflow)
        
        # æ·»åŠ æ¡ä»¶è¾¹
        self._add_conditional_edges(workflow)
        
        subgraph = workflow.compile()
        print("âœ… å­å›¾æ„å»ºå®Œæˆ")
        return subgraph
    
    def _add_nodes(self, workflow: StateGraph):
        """æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹"""
        workflow.add_node("search", lambda s: search_node(s, self.llm))
        workflow.add_node("write", lambda s: write_section_node(s, self.llm))
        workflow.add_node("reflect", lambda s: reflector_node(s, self.llm))
        workflow.add_node("format_output", self._create_format_output_node())
    
    def _add_edges(self, workflow: StateGraph):
        """æ·»åŠ æ™®é€šè¾¹"""
        workflow.add_edge(START, "search")
        workflow.add_edge("search", "write")
        workflow.add_edge("write", "reflect")
        workflow.add_edge("format_output", END)
    
    def _add_conditional_edges(self, workflow: StateGraph):
        """æ·»åŠ æ¡ä»¶è¾¹"""
        workflow.add_conditional_edges(
            "reflect",
            should_continue,  # ä½¿ç”¨æ—¢æœ‰çš„æ¡ä»¶å‡½æ•°
            {
                "end": "format_output",
                "search": "search",
                "rewrite": "write"
            }
        )
    
    def _create_format_output_node(self) -> Callable:
        """
        åˆ›å»º format_output èŠ‚ç‚¹
        
        ä½œç”¨: æŠŠæ®µè½å†…å®¹å’Œæœç´¢ç»“æœæ‰“åŒ…æˆ SectionOutput
        """
        def format_output(state: SectionState):
            section_def = state['section_def']
            title = (
                section_def['title'] 
                if isinstance(section_def, dict) 
                else section_def.title
            )
            
            output_data = {
                "title": title,
                "content": state['current_content'],
                "local_refs": state.get('search_results', [])
            }
            
            return {
                "completed_sections": [output_data]
            }
        
        return format_output


class MainGraphBuilder:
    """ä¸»å›¾æ„å»ºå™¨"""
    
    def __init__(self, llm, subgraph: Any):
        self.llm = llm
        self.subgraph = subgraph
        self.config = MAIN_GRAPH_TOPOLOGY
    
    def build(self) -> Any:
        """
        æ„å»ºä¸»å›¾
        
        æ‹“æ‰‘:
            START â†’ generate_structure â†’ [Send] section_worker â†’ compile â†’ END
        """
        print("ğŸ”¨ æ„å»ºä¸»å›¾ (MainGraph)...")
        
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        self._add_nodes(workflow)
        
        # æ·»åŠ è¾¹
        self._add_edges(workflow)
        
        # æ·»åŠ æ¡ä»¶è¾¹
        self._add_conditional_edges(workflow)
        
        main_graph = workflow.compile()
        print("âœ… ä¸»å›¾æ„å»ºå®Œæˆ")
        return main_graph
    
    def _add_nodes(self, workflow: StateGraph):
        """æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹"""
        workflow.add_node("generate_structure", lambda s: generate_structure_node(s, self.llm))
        workflow.add_node("section_worker", self.subgraph)
        workflow.add_node("compile", self._create_compile_node())
    
    def _add_edges(self, workflow: StateGraph):
        """æ·»åŠ æ™®é€šè¾¹"""
        workflow.add_edge(START, "generate_structure")
        workflow.add_edge("section_worker", "compile")
        workflow.add_edge("compile", END)
    
    def _add_conditional_edges(self, workflow: StateGraph):
        """æ·»åŠ æ¡ä»¶è¾¹"""
        workflow.add_conditional_edges(
            "generate_structure",
            self._map_sections_to_workers,
            ["section_worker"]
        )
    
    def _create_compile_node(self) -> Callable:
        """
        åˆ›å»º compile_report èŠ‚ç‚¹
        
        ä½œç”¨: æ±‡æ€»æ‰€æœ‰æ®µè½ï¼Œç”Ÿæˆå…¨å±€å¼•ç”¨æ˜ å°„ï¼Œæ›¿æ¢æœ¬åœ°å¼•ç”¨ä¸ºï¿½ï¿½å±€å¼•ç”¨
        """
        def compile_report(state: AgentState):
            sections_data = state.get("completed_sections", [])
            
            # --- é˜¶æ®µ 1: æ„å»ºå…¨å±€å¼•ç”¨åº“ ---
            global_refs = []
            url_to_global_id = {}
            
            # éå†æ‰€æœ‰æ®µè½ï¼Œæ”¶é›†æ‰€æœ‰å¼•ç”¨
            for sec in sections_data:
                local_refs = sec.get("local_refs", [])
                
                for ref in local_refs:
                    url = ref.get('url', '')
                    title = ref.get('title', 'æœªçŸ¥')
                    
                    # ç”Ÿæˆå”¯ä¸€é”®
                    unique_key = (
                        url 
                        if url and len(url) > 5 and "æœ¬åœ°" not in url 
                        else title
                    )
                    
                    # å»é‡
                    if unique_key not in url_to_global_id:
                        new_id = len(global_refs) + 1
                        url_to_global_id[unique_key] = new_id
                        global_refs.append(ref)
            
            # --- é˜¶æ®µ 2: é‡å†™æ­£æ–‡ä¸­çš„å¼•ç”¨ ID ---
            final_content_parts = []
            
            for sec in sections_data:
                original_text = sec["content"]
                local_refs = sec.get("local_refs", [])
                
                # å»ºç«‹å±€éƒ¨ ID â†’ å…¨å±€ ID æ˜ å°„
                local_id_map = {}
                for i, ref in enumerate(local_refs, 1):
                    url = ref.get('url', '')
                    title = ref.get('title', 'æœªçŸ¥')
                    
                    unique_key = (
                        url 
                        if url and len(url) > 5 and "æœ¬åœ°" not in url 
                        else title
                    )
                    
                    if unique_key in url_to_global_id:
                        global_id = url_to_global_id[unique_key]
                        local_id_map[i] = global_id
                
                # æ­£åˆ™æ›¿æ¢: [1] â†’ [3] (ä¾‹å¦‚)
                def replace_match(match):
                    local_num = int(match.group(1))
                    global_num = local_id_map.get(local_num, local_num)
                    return f"[{global_num}]"
                
                fixed_text = re.sub(r'\[(\d+)\]', replace_match, original_text)
                
                # å¯¹æ­£æ–‡ä¸­çš„é‡å¤å¼•ç”¨è¿›è¡Œå»é‡å¤„ç†
                fixed_text = self._deduplicate_consecutive_citations(fixed_text)
                
                final_content_parts.append(f"## {sec['title']}\n\n{fixed_text}")
            
            # --- é˜¶æ®µ 3: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š ---
            body = (
                f"# {state.get('query', 'ç ”ç©¶æŠ¥å‘Š')}\n\n" +
                "\n\n---\n\n".join(final_content_parts)
            )
            
            # ç”Ÿæˆæ–‡æœ«å¼•ç”¨åˆ—è¡¨
            ref_section = ""
            if global_refs:
                ref_section = "\n\n### å‚è€ƒèµ„æ–™ / References\n"
                for i, ref in enumerate(global_refs, 1):
                    title = ref.get('title', 'æœªçŸ¥æ¥æº')
                    url = ref.get('url', '')
                    
                    line = f"- [{i}] {title}"
                    if url and "æœ¬åœ°" not in url:
                        line += f"  ([é“¾æ¥]({url}))"
                    
                    ref_section += line + "\n"
            
            return {"final_report": body + ref_section}
        
        return compile_report
    
    def _deduplicate_consecutive_citations(self, text: str) -> str:
        """
        å»é‡è¿ç»­å‡ºç°çš„ç›¸åŒå¼•ç”¨å·
        
        å¤„ç†ä»¥ä¸‹æƒ…å†µï¼š
        - [[1]] [[1]] [[2]] â†’ [[1]] [[2]]
        - [[4]]ã€[[4]]ã€[[9]] â†’ [[4]]ã€[[9]]  (ä¿ç•™åˆ†éš”ç¬¦)
        - [1] [1] [2] â†’ [1] [2]
        - [[4]] [[5]] [[7]] [[4]] â†’ [[4]] [[5]] [[7]]ï¼ˆå»é™¤äº¤é”™é‡å¤ï¼‰
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            å»é‡åçš„æ–‡æœ¬
        """
        
        def deduplicate_double_bracket_consecutive(text):
            """å¤„ç† [[1]] [[1]] æ ¼å¼çš„è¿ç»­é‡å¤"""
            prev_text = ""
            max_iterations = 10
            iteration = 0
            
            while text != prev_text and iteration < max_iterations:
                prev_text = text
                iteration += 1
                
                # åŒ¹é… [[N]]ã€[[N]] æˆ– [[N]] [[N]] è¿™æ ·çš„ç›¸é‚»é‡å¤æ¨¡å¼
                pattern = r'\[\[(\d+)\]\]([\sã€ï¼Œ,]*)\[\[(\d+)\]\]'
                
                def replace_func(match):
                    num1 = match.group(1)
                    separator = match.group(2)
                    num2 = match.group(3)
                    
                    # å¦‚æœä¸¤ä¸ªæ•°å­—ç›¸åŒï¼Œå»æ‰ç¬¬ä¸€ä¸ª
                    if num1 == num2:
                        return f"[[{num1}]]"
                    else:
                        # ä¸ç›¸åŒï¼Œä¿ç•™åŸæ ·
                        return match.group(0)
                
                text = re.sub(pattern, replace_func, text)
            
            return text
        
        def deduplicate_single_bracket_consecutive(text):
            """å¤„ç† [1] [1] æ ¼å¼çš„è¿ç»­é‡å¤"""
            prev_text = ""
            max_iterations = 10
            iteration = 0
            
            while text != prev_text and iteration < max_iterations:
                prev_text = text
                iteration += 1
                
                # åŒ¹é… [N]ã€[N] æˆ– [N] [N] è¿™æ ·çš„ç›¸é‚»é‡å¤æ¨¡å¼
                pattern = r'\[(\d+)\]([\sã€ï¼Œ,]*)\[(\d+)\]'
                
                def replace_func(match):
                    num1 = match.group(1)
                    separator = match.group(2)
                    num2 = match.group(3)
                    
                    # å¦‚æœä¸¤ä¸ªæ•°å­—ç›¸åŒï¼Œå»æ‰ç¬¬ä¸€ä¸ª
                    if num1 == num2:
                        return f"[{num1}]"
                    else:
                        # ä¸ç›¸åŒï¼Œä¿ç•™åŸæ ·
                        return match.group(0)
                
                text = re.sub(pattern, replace_func, text)
            
            return text
        
        # å…ˆå¤„ç† [[N]] æ ¼å¼ï¼ˆè¿ç»­ç›¸é‚»çš„é‡å¤ï¼‰
        text = deduplicate_double_bracket_consecutive(text)
        
        # å†å¤„ç† [[N]] æ ¼å¼ï¼ˆå¼•ç”¨åºåˆ—å—ä¸­çš„äº¤é”™é‡å¤ï¼‰
        # åœ¨ä¸€ä¸ª"å¼•ç”¨åºåˆ—å—"ï¼ˆä¸€è¿ä¸²å¼•ç”¨ï¼Œä¸­é—´ä»…æœ‰ç©ºæ ¼æˆ–åˆ†éš”ç¬¦ï¼‰ä¸­å»é‡
        pattern = r'\[\[\d+\]\](?:[\sã€ï¼Œ,]+\[\[\d+\]\])*'
        
        def deduplicate_block(match):
            block = match.group(0)
            
            # æå–æ‰€æœ‰å¼•ç”¨å·
            citation_pattern = r'\[\[(\d+)\]\]'
            citations = re.findall(citation_pattern, block)
            
            # å¦‚æœæ²¡æœ‰é‡å¤ï¼Œè¿”å›åŸæ ·
            if len(set(citations)) == len(citations):
                return block
            
            # å»é‡ä½†ä¿æŒé¡ºåº
            seen = set()
            unique = []
            for c in citations:
                if c not in seen:
                    seen.add(c)
                    unique.append(c)
            
            # è·å–åˆ†éš”ç¬¦
            sep_match = re.search(r'\]\]([\sã€ï¼Œ,]+)\[\[', block)
            if sep_match:
                sep = sep_match.group(1)
            else:
                sep = ' '
            
            # é‡å»º
            return sep.join([f"[[{c}]]" for c in unique])
        
        text = re.sub(pattern, deduplicate_block, text)
        
        # æœ€åå¤„ç† [N] æ ¼å¼
        text = deduplicate_single_bracket_consecutive(text)
        
        return text
    
    def _map_sections_to_workers(self, state: AgentState) -> List:
        """
        æ˜ å°„æ®µè½åˆ° worker ä»»åŠ¡
        
        ä¸ºæ¯ä¸ªæ®µè½åˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„ Send ä»»åŠ¡ï¼Œå®ç°å¹¶è¡Œå¤„ç†
        """
        sections = state.get("sections", [])
        query = state.get("query", "")
        
        print(f"ğŸ“‹ æ˜ å°„ {len(sections)} ä¸ªæ®µè½åˆ° worker...")
        
        tasks = []
        for sec in sections:
            task = Send("section_worker", {
                "section_def": sec,
                "query": query,
                "iteration_count": 0,
                "search_results": [],
                "current_content": "",
                "is_satisfactory": False,
                "completed_sections": []
            })
            tasks.append(task)
        
        return tasks


class GraphFactory:
    """å›¾å·¥å‚ - ç»Ÿä¸€ç®¡ç†å›¾çš„åˆ›å»º"""
    
    @staticmethod
    def create_graph() -> Any:
        """åˆ›å»ºå®Œæ•´çš„å›¾ï¼ˆå­å›¾ + ä¸»å›¾ï¼‰"""
        # åˆå§‹åŒ– LLM
        config = load_config()
        llm = QwenLLM(api_key=config.dashscope_api_key)
        
        # æ„å»ºå­å›¾
        subgraph_builder = SubGraphBuilder(llm)
        subgraph = subgraph_builder.build()
        
        # æ„å»ºä¸»å›¾
        main_graph_builder = MainGraphBuilder(llm, subgraph)
        main_graph = main_graph_builder.build()
        
        return main_graph